# Proyecto: Clasificaci√≥n de Tuercas, Tornillos y Arandelas (OpenCV cl√°sico)

## üìã Descripci√≥n del Proyecto
Sistema de visi√≥n artificial capaz de clasificar autom√°ticamente piezas mec√°nicas (tuercas, tornillos y arandelas) en im√°genes, independientemente de su orientaci√≥n o √°ngulo de captura.

## üéØ Evoluci√≥n de la Estrategia de Clasificaci√≥n

### ‚ùå Estrategia Inicial (Compleja - Descartada)
```
DETECCI√ìN POR √ÅNGULO + MODELOS ESPECIALIZADOS
‚îú‚îÄ‚îÄ Dataset dividido por √°ngulos
‚îÇ   ‚îú‚îÄ‚îÄ frontal/
‚îÇ   ‚îú‚îÄ‚îÄ lateral/
‚îÇ   ‚îî‚îÄ‚îÄ angulado/
‚îú‚îÄ‚îÄ M√∫ltiples clasificadores
‚îÇ   ‚îú‚îÄ‚îÄ ClasificadorFrontal
‚îÇ   ‚îú‚îÄ‚îÄ ClasificadorLateral
‚îÇ   ‚îî‚îÄ‚îÄ ClasificadorAngulado
‚îî‚îÄ‚îÄ Sistema de ensamble complejo
```
Problemas identificados:
- Complejidad excesiva: demasiados modelos y reglas.
- Fragilidad: si falla la detecci√≥n de √°ngulo, se propagan errores.
- Mantenimiento dif√≠cil: varios modelos a actualizar y versionar.
- Sobreenfocamiento: modelos muy espec√≠ficos pierden generalizaci√≥n.
- Dataset artificial: en la pr√°ctica, las im√°genes vienen mezcladas.

### ‚úÖ Estrategia Final (Simplificada - Implementada)
```
CARACTER√çSTICAS ROBUSTAS + CLASIFICACI√ìN √öNICA
‚îú‚îÄ‚îÄ Dataset simple por clase
‚îÇ   ‚îú‚îÄ‚îÄ tuercas/
‚îÇ   ‚îú‚îÄ‚îÄ tornillos/
‚îÇ   ‚îî‚îÄ‚îÄ arandelas/
‚îú‚îÄ‚îÄ Un clasificador principal
‚îÇ   ‚îî‚îÄ‚îÄ ClasificadorPiezas
‚îú‚îÄ‚îÄ Caracter√≠sticas multi-√°ngulo
‚îÇ   ‚îî‚îÄ‚îÄ Invariantes a rotaci√≥n
‚îî‚îÄ‚îÄ Reglas de backup simples
```
Ventajas:
- Simplicidad: un solo modelo f√°cil de mantener.
- Robustez: caracter√≠sticas que funcionan en cualquier √°ngulo.
- Generalizaci√≥n: mejor rendimiento en casos nuevos.
- Mantenibilidad: f√°cil de depurar y mejorar.
- Realismo: se adapta a datasets del mundo real.

## üìÅ Estructura y Archivos Clave

Estructura de carpetas esperada:
```
dataset/
  arandelas/
  tornillos/
  tuercas/
modelos/
resultados/
codigo/
  config.py
  utils.py
  preprocesamiento.py
  segmentacion.py
  extraccion_caracteristicas.py
  clasificacion.py
  evaluacion.py
	main.py
```

Descripci√≥n de archivos:
1) `codigo/config.py` (‚öôÔ∏è): Configuraci√≥n centralizada.
	- Tama√±os de imagen y preprocesamiento
	- Umbrales para segmentaci√≥n/filtrado y reglas
	- Hiperpar√°metros de SVM/KNN/Random Forest
	- Rutas del dataset y modelos (por defecto `./dataset`, `./modelos`)

2) `codigo/utils.py` (üõ†Ô∏è): Utilidades generales.
	- Carga de dataset, guardado/carga de modelos, visualizaci√≥n de contornos
	- Manejo de directorios y guardado de im√°genes procesadas

3) `codigo/preprocesamiento.py` (üñºÔ∏è): Preparaci√≥n de im√°genes.
	- Redimensionado, conversi√≥n a gris, filtro gaussiano, ecualizaci√≥n, normalizaci√≥n
	- Operaciones morfol√≥gicas y binarizaci√≥n (Otsu)

4) `codigo/segmentacion.py` (‚úÇÔ∏è): Detecci√≥n de objetos.
	- Umbralizaci√≥n Otsu, contornos `RETR_EXTERNAL + CHAIN_APPROX_SIMPLE`
	- Filtrado por √°rea y relaci√≥n de aspecto, extracci√≥n de ROI, orientaci√≥n b√°sica

5) `codigo/extraccion_caracteristicas.py` (üîç): Descriptores de forma y textura.
	- Relaci√≥n de aspecto, solidez, circularidad, compacidad, rectangularidad, excentricidad
	- Aristas (pol√≠gono aproximado), detecci√≥n de agujero, momentos de Hu, textura/uniformidad

6) `codigo/clasificacion.py` (üß†): Clasificaci√≥n ML + reglas.
	- SVM/KNN/RandomForest con `StandardScaler`
	- Clasificaci√≥n por reglas (backup) y combinaci√≥n ML+reglas

7) `codigo/evaluacion.py` (üìä): M√©tricas y an√°lisis.
	- Accuracy, precisi√≥n, recall, F1, matriz de confusi√≥n, curvas de aprendizaje
	- Evaluaci√≥n por clase y reporte de errores visual


8) `codigo/main.py` (üéÆ): Orquestador CLI.
	- `--entrenar`, `--predecir`, `--evaluar`, `--evaluar-todo` y `--modelo [svm|knn|rf]`
	- `--tune` para activar GridSearchCV (b√∫squeda de hiperpar√°metros)
	- `--debug N` para guardar N ejemplos por clase (binarizados y contornos)
	- Nota: el `main.py` reside dentro de `codigo/`. Las rutas (`./dataset`, `./modelos`, `./resultados`) se resuelven autom√°ticamente respecto a la ra√≠z del proyecto, independientemente del directorio actual.

## üîÑ Flujo de Procesamiento
```
IMAGEN ORIGINAL
	 ‚Üì
preprocesamiento.py      ‚Üí Mejora calidad
	 ‚Üì
segmentacion.py          ‚Üí Detecta objetos
	 ‚Üì
extraccion_caracteristicas.py ‚Üí Extrae features
	 ‚Üì
clasificacion.py         ‚Üí Clasifica pieza
	 ‚Üì
RESULTADO: "tuerca" | "tornillo" | "arandela"
```

## üì¶ Requisitos e Instalaci√≥n

Requisitos m√≠nimos: Python 3.10+, Linux/macOS/Windows.

Instala dependencias (recomendado en un entorno virtual):
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
pip install -r requirements.txt
```

Si tienes problemas al mostrar/guardar im√°genes con OpenCV en Linux, instala `libgl1`:
```bash
sudo apt-get update && sudo apt-get install -y libgl1
```

## ‚ñ∂Ô∏è C√≥mo Ejecutar

Entrenamiento (SVM por defecto):
```bash
# desde la ra√≠z del proyecto
python codigo/main.py --entrenar --modelo svm

# o situ√°ndote dentro de 'codigo/'
cd codigo && python main.py --entrenar --modelo svm
```

Predicci√≥n sobre una imagen:
```bash
# desde la ra√≠z del proyecto
python codigo/main.py --predecir ./dataset/tuercas/ejemplo.jpg --modelo svm
```

Evaluaci√≥n de un modelo existente:
```bash
# desde la ra√≠z del proyecto
python codigo/main.py --evaluar --modelo svm
# alias expl√≠cito para evaluar TODO el dataset
python codigo/main.py --evaluar-todo --modelo svm
```

Notas:
- Estructura del dataset: coloca im√°genes directamente dentro de `dataset/arandelas`, `dataset/tornillos`, `dataset/tuercas` (sin subcarpetas por √°ngulo). El c√≥digo resuelve `./dataset` siempre respecto a la ra√≠z del repo, aunque ejecutes desde `codigo/`.
- Los modelos se guardan en `./modelos/` y resultados/figuras en `./resultados/`.
- Si `scikit-learn` no est√° instalado, el sistema puede degradarse a reglas simples.

### Modos de entrenamiento y flags

- B√°sico (r√°pido):
	- `python codigo/main.py --entrenar --modelo svm`
	- Entrena un pipeline con StandardScaler + SVM/KNN/RF usando par√°metros de `config.py`.

- Con b√∫squeda de hiperpar√°metros (recomendado para subir accuracy):
	- `python codigo/main.py --entrenar --modelo svm --tune`
	- Ejecuta GridSearchCV con las parrillas de `config.py` (`GRID_SVM`, `GRID_KNN`, `GRID_RF`), selecciona el mejor estimador y lo deja guardado en el pipeline.

- Con depuraci√≥n de segmentaci√≥n (ahorra iteraciones de ajuste):
	- `python codigo/main.py --entrenar --modelo svm --debug 5`
	- Guarda 5 ejemplos por clase de binarizados y contornos en `resultados/debug_entrenamiento_<timestamp>/` para inspeccionar si la segmentaci√≥n descarta o confunde piezas.

### Evaluaci√≥n e informes

Al ejecutar evaluaci√≥n se crea una carpeta por ejecuci√≥n:

```
resultados/estadisticas_evaluaciones/<YYYY-MM-DD_HH-MM-SS>/
	‚îú‚îÄ‚îÄ metricas_<modelo>.txt             # accuracy, precision_macro, recall_macro, f1_macro, f1_weighted
	‚îú‚îÄ‚îÄ classification_report.txt         # reporte detallado por clase
	‚îú‚îÄ‚îÄ confusion_matrix.png              # matriz de confusi√≥n
	‚îú‚îÄ‚îÄ per_class_metrics.png             # barras de precision/recall/f1 por clase
	‚îú‚îÄ‚îÄ predictions.csv                   # filas: ruta,real,pred (cada imagen procesada)
	‚îî‚îÄ‚îÄ coverage.txt                      # total, procesadas, saltadas y listado de saltadas (hasta 200)
```

Adem√°s, al final de la evaluaci√≥n se imprime el Accuracy en consola y queda registrado en logs.

## üî¨ Caracter√≠sticas extra√≠das (features)

- Geom√©tricas: relaci√≥n de aspecto, solidez, circularidad, compacidad, rectangularidad, excentricidad.
- Estructurales: n√∫mero de lados aproximado (approxPolyDP), √≠ndice de aristas (hexagonal‚âà1), relaci√≥n de agujero.
- Invariantes (Hu): 7 momentos de Hu con log-transform y signo.
- Textura: suavidad (std normalizada) y uniformidad (energ√≠a del histograma) sobre ROI.
- HOG (opcional, activado por defecto):
	- Se calcula sobre el ROI con padding (`ROI_PADDING`) para capturar bordes del objeto.
	- Par√°metros en `config.py`: `HOG_ORIENTACIONES`, `HOG_PIXELS_PER_CELL`, `HOG_CELDAS_X`, `HOG_CELDAS_Y`.

El ROI se extrae del contorno mayor tras filtros por √°rea y relaci√≥n de aspecto; puede expandirse con `ROI_PADDING` para capturar el objeto completo antes de HOG/texture.

## ‚öôÔ∏è Segmentaci√≥n y par√°metros importantes (config.py)

- Umbralizaci√≥n: Otsu por defecto (`UMBRAL_OTSU=True`). Alternativas: `binarizar_imagen(..., metodo='adaptive' | 'binary')`.
- Morfolog√≠a post-umbral (recomendado):
	- `MORFOLOGIA_POST_UMBRAL=True`, `MORFOLOGIA_OPERACION="cierre"`, `MORFOLOGIA_KERNEL=3|5`.
	- Mejora m√°scaras, une bordes y reduce ruido.
- Filtro por √°rea: `AREA_MIN`, `AREA_MAX` para descartar ruido o objetos min√∫sculos.
- Filtro por aspecto: `ASPECTO_MIN`, `ASPECTO_MAX` para suprimir contornos muy extremos.
- ROI con padding: `ROI_PADDING` (p.ej., 0.05) para no recortar bordes √∫tiles del objeto.

## üß† Modelos y tuning

- SVM (por defecto): `SVM_PARAMS` con `class_weight='balanced'` y `probability=True`.
- KNN: `KNN_PARAMS` (vecinos, m√©trica, weights).
- Random Forest: `RF_PARAMS` con `class_weight='balanced'`.
- Grid search (`--tune`) usa:
	- `GRID_SVM`: C, gamma, kernel.
	- `GRID_KNN`: n_neighbors, weights, p.
	- `GRID_RF`: n_estimators, max_depth, max_features.

## üß≠ C√≥mo subir el accuracy (gu√≠a r√°pida)

1) Segmentaci√≥n primero:
	 - Activa morfolog√≠a y ajusta `MORFOLOGIA_KERNEL` (3‚Üí5) si ves huecos o cortes.
	 - Ajusta `AREA_MIN` para no descartar piezas peque√±as ni aceptar ruido.
	 - Revisa `ASPECTO_MIN/MAX` si hay variabilidad alta.
	 - Usa `--debug 5` para generar binarizados/contornos por clase y ajustar r√°pido.

2) ROI + HOG:
	 - Asegura `USE_HOG=True` y que el ROI tenga `ROI_PADDING` suficiente para no cortar bordes.
	 - Ajusta rejilla HOG (`HOG_CELDAS_X/Y`) y bins (`HOG_ORIENTACIONES`).

3) Tuning de modelo:
	 - Lanza `--tune` con SVM; guarda el mejor estimador autom√°ticamente.
	 - Si hay desbalance, `class_weight='balanced'` ya viene activado en SVM/RF.

4) Validaci√≥n:
	 - Revisa `classification_report.txt` y `confusion_matrix.png` en cada ejecuci√≥n.
	 - Si una clase falla mucho, considera m√°s datos o ajustar umbrales/ROI.

## üéØ Caracter√≠sticas Clave del Dise√±o Final
1) Robustez Angular (üåÄ): caracter√≠sticas geom√©tricas invariantes a rotaci√≥n; no depende de la orientaci√≥n.
2) Clasificaci√≥n H√≠brida (‚ö°): ML para patrones complejos; reglas simples como respaldo.
3) Mantenibilidad (üîß): configuraci√≥n centralizada, m√≥dulos desacoplados, f√°cil de depurar.
4) Escalabilidad (üìà): sencillo a√±adir nuevas clases y evaluar el impacto.

## üöÄ Resultados Esperados (objetivos)
| M√©trica               | Objetivo |
|-----------------------|----------|
| Accuracy general      | > 80%    |
| Precisi√≥n tuercas     | > 85%    |
| Recall tornillos      | > 75%    |
| F1-score arandelas    | > 80%    |

## üí° Lecciones Aprendidas
- Simplicidad > Complejidad: menos componentes, menos puntos de fallo.
- Caracter√≠sticas robustas > muchos modelos espec√≠ficos.
- Dataset real > dataset ideal: adaptarse a los datos disponibles.
- Sistema h√≠brido > enfoque puro: ML + reglas = mejor robustez.

## üß™ Consejos y Troubleshooting
- "No hay contornos": revisa iluminaci√≥n y binarizaci√≥n; prueba `pre.binarizar_imagen(..., metodo='adaptive')`.
- "predict_proba no disponible": habilitado para SVM con `probability=True` (por defecto en `config`).
- "No module named sklearn": ejecuta `pip install -r requirements.txt` en tu entorno.

## üìà Experiencias, problemas y soluciones aplicadas

Durante el desarrollo se observaron dos escenarios relevantes que impactaban al rendimiento:

1) Baja cobertura de procesamiento (muchas im√°genes saltadas)
	 - S√≠ntomas: `coverage.txt` mostraba muy pocas `procesadas` y muchas `saltadas` (p. ej., 71/472 procesadas; 401 saltadas).
	 - Causas probables: binarizaci√≥n no robusta a iluminaci√≥n/fondo, morfolog√≠a insuficiente, filtros de √°rea/aspecto demasiado estrictos.
	 - Soluciones implementadas:
		 - Segmentaci√≥n robusta: se intentan m√∫ltiples m√©todos de binarizaci√≥n (Otsu, adaptativa, binaria fija), con y sin inversi√≥n, y distintas morfolog√≠as (kernel 3/5/7).
		 - Relajaci√≥n progresiva: se relajan umbrales de √°rea y aspecto por etapas si no se encuentran contornos v√°lidos.
		 - Resultado: cobertura 100% (0 saltadas) en el dataset de ejemplo.

2) Ca√≠da de accuracy tras aumentar cobertura
	 - S√≠ntomas: al pasar a 0 saltadas el accuracy cay√≥ (p. ej., ~0.41) por mayor ruido en las muestras procesadas.
	 - Causas probables: contornos sub√≥ptimos elegidos (fondo, sombras), alta dimensionalidad de HOG y ruido.
	 - Soluciones implementadas:
		 - Selecci√≥n de contorno por score de calidad: se elige el mejor contorno seg√∫n combinaci√≥n de solidez, rectangularidad y √°rea, evitando tomar contornos de mala calidad aunque pasen filtros.
		 - PCA opcional en el pipeline: reducci√≥n de dimensionalidad antes del clasificador (√∫til con HOG) para mejorar la generalizaci√≥n y reducir ruido. Controlable v√≠a `USE_PCA`, `PCA_COMPONENTS` y `PCA_WHITEN` en `config.py`.
		 - Re-entrenar con `--tune`: GridSearchCV para hallar hiperpar√°metros adecuados con validaci√≥n cruzada, clave tras cambios de features/segmentaci√≥n.

### Recomendaciones de entrenamiento/validaci√≥n

- Mant√©n validaci√≥n honesta mientras buscas hiperpar√°metros:
	- Usa `--tune` para GridSearchCV (CV interna).
	- No entrenes con todo el dataset hasta fijar hiperpar√°metros con CV.

- Modelo final (para despliegue):
	- Una vez elegidos hiperpar√°metros, reentrena con todo el dataset de entrenamiento (puedo a√±adir `--entrenar-final` si lo deseas).

### Par√°metros √∫tiles a ajustar en `config.py`

- Segmentaci√≥n:
	- `MORFOLOGIA_POST_UMBRAL=True`, `MORFOLOGIA_OPERACION="cierre"`, `MORFOLOGIA_KERNEL=3|5|7`
	- `AREA_MIN`, `AREA_MAX` (objetos muy peque√±os o grandes)
	- `ASPECTO_MIN`, `ASPECTO_MAX` (variabilidad de formas)
	- `ROI_PADDING` (evitar recortes demasiado ajustados)

- Features (HOG/Dimensionalidad):
	- `USE_HOG=True`, `HOG_ORIENTACIONES`, `HOG_PIXELS_PER_CELL`, `HOG_CELDAS_X/Y`
	- `USE_PCA=True`, `PCA_COMPONENTS=100`, `PCA_WHITEN=False`

- Clasificadores/Tuning:
	- `SVM_PARAMS`, `KNN_PARAMS`, `RF_PARAMS`
	- `GRID_SVM`, `GRID_KNN`, `GRID_RF` para `--tune`

### Auditor√≠a de resultados por ejecuci√≥n

Cada evaluaci√≥n crea una carpeta con timestamp en `resultados/estadisticas_evaluaciones/<fecha_hora>/` con:

- `metricas_<modelo>.txt`, `classification_report.txt`, `confusion_matrix.png`, `per_class_metrics.png`
- `predictions.csv`: (ruta, real, pred) para revisar errores concretos.
- `coverage.txt`: total/procesadas/saltadas, y listado de saltadas (hasta 200) con motivo (p. ej., `sin_caracteristicas`).

Usa estos archivos para localizar patrones de error por clase o por condiciones de imagen (iluminaci√≥n, foco, fondo).

